<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Feature Collections</title>
<style type="text/css">
pre {font-size: 9pt; padding: 10px; background-color: #E7E7E7; border: 1px solid #CFCFCF; width: 85%;}
code {font-size: 11pt;}
dl {margin: 10px 5px 5px 15px;)
.style1 {font-style: italic}
</style>
</head>

<body>
<h1>Feature Collections</h1>
<p><em>Experimental design doc</em></p>
<p><em>last updated: 4/08/2010</em></p>
<p>Feature Collections are introduced in CDM version 4.2, as a way to specify collections of <a href="../FeatureDatasets/Overview.html">Feature Datasets</a>. Currently this can be used in PointFeature Collections and <a href="Fmrc.html">FMRC</a> (Forecast Model Run Collections). </p>
<p>Management of the set of datasets in a Feature Collection has been factored out into the CollectionManager class.</p>
<h2>CollectionManager</h2>
<h3>Create from a collection specification</h3>
<p>A<a href="CollectionSpecification.html"> <em><strong>collection specification</strong></em></a><em><strong> string</strong></em> is a simple way to create a collection. </p>
<pre>
/data/ldm/pub/native/grid/NCEP/GFS/Alaska_191km/**/GFS_Alaska_191km_#yyyyMMdd_HHmm#\.grib1$</pre>
<ul>
  <li>rootDir= /data/ldm/pub/native/grid/NCEP/GFS/Alaska_191km</li>
  <li>subdirs= yes </li>
  <li>dateFormatMark= GFS_Alaska_191km_#yyyyMMdd_HHmm</li>
  <li>onName= yes</li>
  <li>regexp= GFS_Alaska_191km.........\.grib1$</li>
</ul>
<h3>Create from a catalog</h3>
<p>You can use a <em><strong>catalog:catalogURL</strong></em>. All the datasets in the catalog are used, using best remote access capabilty, currently OPeNDAP. See <strong>DatasetCollectionFromCatalog</strong> class.</p>
<h3>Create from NcML</h3>
<p>If you pass an ncml file (must end in <strong>.ncml</strong>) the NcML is parsed, and the scan or scanFmrc is extracted. A <strong>DatasetCollectionFromNcml </strong>is returned, along with inner and outer JDOM NcML elements.</p>
<h2>PointFeature Collection in CDM 4.1 library</h2>
<p><strong>FeatureDatasetFactoryManager.open(location, wantFeatureType)</strong> looks for <em><strong>collection:spec</strong></em> prefix for the location, and calls <strong>CompositeDatasetFactory.factory(wantFeatureType, spec)</strong> if found, which returns a FeatureDataset. Currently only a limited number of Point Feature types are supported. This is an experimental feature</p>
<h2>Proposed elements in TDS Configuration catalogs<a name="TDS" id="TDS"></a></h2>
<h3>collection element</h3>
<p>Defines the collection of datasets and provides some control over dynamically changing datasets. Takes the place of NcML aggregation element (scan and scanFmrc). Eventually this will also replace datasetScan (?).</p>
<pre>&lt;<strong>collection</strong> <strong>spec</strong>=&quot;/data/ldm/pub/native/satellite/3.9/WEST-CONUS_4km/WEST-CONUS_4km_3.9_#yyyyMMdd_HHmm#.gini&quot;
            <strong>olderThan</strong>=&quot;1 min&quot; <strong></strong><strong>recheckAfter</strong>=&quot;15 min&quot; /&gt;
</pre>
<blockquote>
  <p>where</p>
  <ol>
    <li><strong>spec</strong>: <a href="CollectionSpecification.html">collection specification</a> string. In this case, all files in the directory <em>/data/ldm/pub/native/satellite/3.9/WEST-CONUS_4km/ </em>whose filename matches the reqular expression WEST-CONUS_4km_3.9_........_....\.gini$&quot;. The  time coordinate (runtime if its an FMRC) of the file will be found by matching <em>yyyyMMdd_HHmm</em> to that portion of the filename.</li>
    <li><strong>olderThan</strong>: only files whose lastModified date is older than this are included. This excludes files that are in the process of being written.</li>
    <li><strong>recheckAfter</strong>: This will cause a directory scan whenever a request comes in and this much time has elapsed since the last scan. The request will wait until the rescan is finished and a new collection is built (if needed). This minimizes unneeded processing for lightly used collections.</li>
  </ol>
</blockquote>
<h3>update element</h3>
<p>For collections that change, provides options to update the collection in a background task. New collections are built in the background, so that requests do not wait.</p>
<pre>&lt;update startup=&quot;true&quot; <strong>rescan</strong>=&quot;cron expr&quot;<strong> </strong>trigger=&quot;allow&quot; <strong></strong>/&gt;
</pre>
<blockquote>
  <p> where: </p>
  <ol>
    <li><strong>startup</strong>= if true, when the server starts up, scan the collection and cache the results.</li>
    <li><strong>rescan</strong>= &quot;cron expr&quot; uses a <a href="http://www.quartz-scheduler.org/docs/tutorials/crontrigger.html">cron expression</a> to specify when the collection should be rescanned in a background task.</li>
    <li><strong>trigger</strong>: if &quot;allow&quot;, then external triggering will be allowed. This allows collections to be updated only when needed, at the cost of an external program (or person) having responsibility for sending the trigger.</li>
  </ol>
</blockquote>
<h3>manage element</h3>
<p>This instructs the TDS to manage your collection by deleting files that are older than a certain time.</p>
<pre>&lt;manage deleteAfter<strong></strong>=&quot;30 days&quot;<strong> </strong><strong>check</strong>=&quot;cron expr&quot; /&gt;
</pre>
<blockquote>
  <p> where: </p>
  <ol>
    <li><strong>deleteAfter</strong>= delete files older than this amount</li>
    <li><strong>check</strong>= &quot;cron expr&quot; uses a <a href="http://www.quartz-scheduler.org/docs/tutorials/crontrigger.html">cron expression</a> to specify when the collection should be checked for old files.</li>
  </ol>
</blockquote>
<h3>protoDataset element</h3>
<p>Provides control over the choice of the prototype dataset for the collection.</p>
<pre>&lt;protoDataset <strong>choice</strong>=&quot;First | Random | Penultimate | Latest&quot; <strong>change</strong>=&quot;expr&quot; /&gt;</pre>
<pre>
&lt;protoDataset&gt;filename&lt;/protoDataset&gt;</pre>
<blockquote>
  <p>  where:  </p>
  <ol>
    <li><strong>choice</strong>=&quot;First | Random | Penultimate | Latest&quot; : select prototype from a time ordered list</li>
    <li> <strong>change</strong> = &quot;cron expr&quot; uses a <a href="http://www.quartz-scheduler.org/docs/tutorials/crontrigger.html">cron expression</a></li>
    <ul>
      <li><em>change = &quot;0 2 3 * * ? *&quot;</em> means every day at 3.02 am.</li>
      <li>if not specified, the prototype dataset is not changed, except on a reboot</li>
    </ul>
    <li>&lt;protoDataset&gt;filename&lt;/protoDataset&gt;allows you to specify a specific file as the prototype.</li>
  </ol>
</blockquote>
<p>On rolling datsets, you will want to change the prototype, otherwise it will get deleted eventually</p>
<h2>Proposed elements for FMRC Feature Collections<a name="TDS" id="TDS2"></a></h2>
<p>There is no need to specify <strong>forecastModelRunCollection</strong> vs <strong>forecastModelRunSingleCollection</strong>, nor <strong>timeUnitsChange</strong>. This is detected automatically. See <a href="http://www.unidata.ucar.edu/software/netcdf/ncml/v2.2/FmrcAggregation.html">FMRC Aggregation</a> and <a href="http://www.unidata.ucar.edu/staff/caron/presentations/FmrcPoster.pdf">poster</a> for background.</p>
<h3>fmrcConfig element</h3>
<p>Defines options on feature collections with <strong> featureType</strong>=&quot;FMRC&quot;.</p>
<pre>&lt;fmrcConfig regularize=&quot;true&quot; datasetTypes=&quot;TwoD Best Files Runs&quot; /&gt;</pre>
<br />
<pre>
&lt;fmrcConfig regularize=&quot;true&quot; datasetTypes=&quot;Files&quot;&gt;
  &lt;dataset name=&quot;Best&quot; offsetsGreaterEqual=&quot;0&quot;/&gt;
&lt;/fmrcCollection</pre>
<blockquote>
  <p>where:</p>
  <ol>
    <li>
      <strong>regularize</strong>: If true, then the runs for a given  hour from( 0Z) are assumed to have the same forecast time coordinates. For example, if you have 4 model runs per day (eg 0, 6, 12, 18Z) and many days of model runs, then all the 6Z runs for all days will have the same time coordiantes, etc. This &quot;regularizes&quot;  time coordinates, and is useful when there may be missing forecast times, instead of creating a new time coordinate. This obviates the need for the FMRC definition files which previously were used on motherlode  for models in the IDD feed. </li>
    <li><strong>datasetTypes</strong>: list the <a href="http://www.unidata.ucar.edu/software/netcdf/ncml/v2.2/FmrcAggregation.html">dataset types</a> that are  exposed in the TDS catalog. The possible values are:
      <ul>
        <li><em>TwoD</em>: dataset with two time dimensions (run time and forecast time), which contains all the data in the collection.</li>
        <li><em>Best</em>: dataset using the latest model data available for each possible forecast hour.</li>
        <li><em>Files</em>: each component file of the collection is available seperately, as in a datasetScan.</li>
        <li><em>Runs</em>:  A<em><strong> model run dataset</strong></em> contains all the data for one run time.</li>
        <li><em>ConstantForecast</em>s:     A <strong><em>constant forecast dataset</em></strong> is created from 
all the data that have the same forecast time. This kind of dataset has successively shorter forecasts of the same endpoint. </li>
        <li><em>ConstantOffsets: </em>A constant offset dataset is created from 
  all the data that have the same offset from the beginning of the run.</li>
      </ul>
    </li>
    <li><strong>dataset</strong>: you can define your own &quot;best dataset&quot;. This uses the same algorithm as the Best dataset above, but may exclude data based on its offset hour. In the above example, a Best dataset is created with offset hours less than 0  excluded.
      <ul>
        <li><strong>name</strong>: the name of the dataset, must be unique within the fmrcConfig element.</li>
        <li><strong>offsetsGreaterEqual</strong>:  offset hours less than this value are excluded.</li>
      </ul>
    </li>
  </ol>
  <p>If there is a serviceType=&quot;HTTPServer&quot; for the Feature Collection, it is removed from the virtual datasets (all except the <em>Files</em> datasets).</p>
  <p>&nbsp;</p>
</blockquote>
<h3>FMRC Homogeneity Requirements</h3>
<ul>
  <li>horizontal coordinates must not change</li>
  <li>vertical coordinates must not change.</li>
</ul>
<h3>Example catalog element:</h3>
<pre>&lt;<strong>featureCollection</strong> <strong>name</strong>=&quot;NCEP-GFS-Alaska_191km&quot; <strong>featureType</strong>=&quot;FMRC&quot; <strong>path</strong>=&quot;fmrc/NCEP/GFS/Alaska_191km&quot;&gt;<br />

   &lt;collection spec=&quot;/data/ldm/pub/native/grid/NCEP/GFS/Alaska_191km/**/GFS_Alaska_191km_#yyyyMMdd_HHmm#.grib1&quot; 
       recheckEvery=&quot;15 min&quot; olderThan=&quot;5 min&quot; /&gt;
   &lt;update startup=&quot;true&quot; /&gt;
<strong>  </strong>&lt;/featureCollection&gt;
have</pre>
<p>If an fmrcConfig element is not present, the default is regularize= <em>false</em>, and  datasetTypes= &quot;<em>TwoD Best Files Run</em>s&quot;. Specifying your own fmrcConfig completely overrides the datasetTypes default.</p>
<p>Note that for the case when a model run dataset is in a single file, it<em> </em> may be different than the same file as seen through the corresponding <em>Files</em> dataset, if <strong>regularize</strong> is on. In that case, the time coordinates will be regularized across all model run datasets in the collection.</p>
<p>If an <em>ID</em> attribute is not specified on the <strong>featureCollection</strong>, the <em>path</em> attribute is used as the ID. This is a preferred idiom.</p>
<h2>Proposed elements for Point Feature Collections</h2>
<p>NOT DONE YET</p>
<p><strong>point data:</strong></p>
<pre>&lt;<strong>featureCollection </strong><strong>name</strong>=&quot;6 minute&quot; <strong>featureType</strong>=&quot;STATION_PROFILE&quot; harvest=&quot;true&quot; <strong>path</strong>=&quot;station/profiler/wind/06min&quot;&gt;<br />  &lt;documentation type=&quot;summary&quot;&gt;Six minute average data.&lt;/documentation&gt;<br />  &lt;collection spec=&quot;/data/ldm/pub/native/profiler/wind/06min/**/PROFILER_wind_06min_#yyyyMMdd#.nc&quot; 
     recheckEvery=&quot;15 min&quot; olderThan=&quot;5 min&quot; /&gt;
&lt;/featureCollection&gt;
</pre>
<p><strong>satellite data:</strong><br />
</p>
<pre>
&lt;<strong>featureCollection name</strong>=&quot;WEST-CONUS_4km&quot; <strong>featureType</strong>=&quot;Grid&quot; <strong>harvest</strong>=&quot;true&quot; <strong>path</strong>=&quot;satellite/3.9/WEST-CONUS_4km&quot;&gt;<br />  &lt;collection spec=&quot;/data/ldm/pub/native/satellite/3.9/WEST-CONUS_4km/WEST-CONUS_4km_3.9_#yyyyMMdd_HHmm#.gini&quot; 
     recheckEvery=&quot;15 min&quot; olderThan=&quot;1 min&quot; /&gt;<br />&lt;/featureCollection&gt;<br />
</pre>
<blockquote>
  <p> where:</p>
  <ol>
    <li><strong>name</strong>: logical name of dataset. Auto generate this and ID if not present ??</li>
    <li><strong>featureType</strong>: required. processing is different for each type</li>
    <li><strong>path</strong>: logical URL of datset, as before</li>
    <li><strong>check</strong>=&quot;demand | startup | background&quot;.
      <ul>
        <li>demand = only scan when a request is made. best for reasonably small datasets only occasionally used.</li>
        <li>startup = on server startup, create collection and cache results. best for static datasets.</li>
        <li>background = rescan collection in a background task <em>recheckEvery</em> amount of time</li>
      </ul>
    </li>
  </ol>
</blockquote>
<h3>Other possible features:</h3>
<ul>
  <li>Allow explicit trigger. Sending a POST to a protected URL forces an update on a <strong>featureCollection</strong>.</li>
  <li>Default services depend on featureType, may be configured by user or overridden in catalog.</li>
  <li>Automatic metadata extraction (time/space BB and variable names)</li>
  <li>Default publisher/author etc added to each catalog.</li>
  <li>Allow references to template metadata</li>
</ul>
<h2>Retrofit NcML</h2>
<p>Currently the new collectionManager code is only used for FMRC aggregations, that is type=<em>forecastModelRunCollection</em> or <em>forecastModelRunSingleCollection</em>.</p>
<pre>
&lt;ncml&gt;
  &lt;modify outer&gt;
  &lt;aggregation&gt;
    &lt;modify inner&gt;
    &lt;scan or scanFmrc&gt;
  &lt;/aggregation&gt;
&lt;/ncml&gt;</pre>
<p>See: <a href="http://www.unidata.ucar.edu/software/netcdf/ncml/v2.2/AnnotatedSchema4.html">NcML annoted schema</a>.</p>

<ol>
  <li>Elements <em><strong>inside</strong></em> the &lt;aggregation&gt; get  applied to each dataset in the aggregation, before it is aggregated.  Elements <em><strong>outside</strong></em> the &lt;aggregation&gt; get applied to the aggregated  dataset.</li>
  <li>Nested netcdf datasets can be implictly specified with a <strong>scan</strong> or <strong>scanFmrc</strong> element. These are now implemented with a CollectionManager.</li>
  <li>If you specify a <strong>regExp</strong>, only files with whose full pathnames match the <a href="#regexp">regular expression</a> will be included.</li>
  <li>If you specify a <strong>suffix</strong>, only files with that ending will be included. A <strong>regExp</strong> attribute will override, that is, you cant specify both.</li>
  <li>You can optionally specify if the scan should  descend into <strong>subdir</strong>ectories (default true).</li>
  <li>If <strong>olderThan</strong> attribute is present, only files whose last modified date are older than this amount of time will be included. This is a way to exclude files that are still being written. This must be a <a href="http://www.unidata.ucar.edu/software/udunits/">udunit</a> time such as &quot;5 min&quot; or &quot;1 hour&quot;. </li>
  <li>A <strong>dateFormatMark</strong> is used on <strong><em>FMRC</em></strong> types to create runtime coordinate values out of the filename. It consists of a section of text, a '#' marking character, then a java.text.<a href="#SimpleDateFormat">SimpleDateFormat</a> string. The number of characters before the # is skipped in the filename, then the next part of the filename must match the SimpleDateFormat string. You can ignore trailing text. For example:
    <pre>
        Filename: SUPER-NATIONAL_1km_SFC-T_20051206_2300.gini 
 DateFormatMark: SUPER-NATIONAL_1km_SFC-T_#yyyyMMdd_HHmm</pre>
      <p><strong>Note that the dateFormatMark works on the name of the file, without the directories!!</strong></p>
  </li>
  <li>A specialized scanFmrc element can be used. In this case, the <strong>runDateMatcher</strong> attribute is used, but the <strong>forecastDateMatcher </strong>and<strong> forecastOffsetMatcher</strong> are no longer used, as the forecast time and offset are obtained from the dataset. The <strong>runDateMatcher</strong> operates on the full path whereas the <strong>dateFormatMark</strong> operated on the filename only.</li>
  <li>When you are using scan elements on a set of files that may change, and you are using caching, set <strong>recheckEvery</strong> to a valid <a href="http://www.unidata.ucar.edu/software/udunits/">udunit</a> time value, like &quot;10 min&quot;, &quot;1 hour&quot;, &quot;30 days&quot;, etc. Whenever the dataset is reacquired from the cache, the directories will be rescanned if <strong>recheckEvery</strong> amount of time has elapsed since the last time it was scanned. If you do not specify a recheckEvery attribute, the collection will be assumed to be non-changing.
    <p>The<strong> recheckEvery</strong> attribute specifies how  out-of-date you are willing to allow your changing datasets to be, not  how often the data changes. If you want updates to be  seen within 5 min, use 5 minutes here, regardless of the frequency of  updating.</p>
  </li>
  <li><strong>timeUnitsChange</strong> is no longer needed or used.</li>
</ol>
<p>&nbsp;</p>
<hr width="100%" />
<address>
<img src="../../nc.gif" width="64" height="64" /> This document is maintained by <a href="mailto:caron@unidata.ucar.edu">John Caron</a> and was last updated  April 16, 2010
</address>
<p>&nbsp; </p>
</body>
</html>
